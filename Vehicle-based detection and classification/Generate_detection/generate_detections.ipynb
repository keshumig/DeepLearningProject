{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ca71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To imports the os module, which provides a way of interacting with the file system.\n",
    "import os\n",
    "# This line imports the errno module, which provides symbolic error codes used by the os module when an error occurs.\n",
    "import errno\n",
    "# This line imports the argparse module, which makes it easy to write user-friendly command-line interfaces for Python programs.\n",
    "import argparse\n",
    "import numpy as np\n",
    "#This line imports the cv2 module, which is a Python wrapper for OpenCV (Open Source Computer Vision Library).\n",
    "import cv2\n",
    "# This line imports the tensorflow module, which is a popular machine learning library developed by Google.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "f: a function that takes in a dictionary of data and returns an array of outputs\n",
    "data_dict: a dictionary of input data\n",
    "out: an array to store the output of f\n",
    "batch_size: the size of each batch to process the data in\n",
    "\n",
    "The function first calculates the total number of batches that will be needed to process all the data. \n",
    "This is done by slicing the input data dictionary (data_dict) for each key-value pair with the start and end indices\n",
    "(s and e) of the current batch.\n",
    "\n",
    "The function then calls the function f on this batch data dictionary and stores the output in the appropriate slice\n",
    "of the output array out.\n",
    "'''\n",
    "\n",
    "def _run_in_batches(f, data_dict, out, batch_size):\n",
    "    data_len = len(out)\n",
    "    num_batches = int(data_len / batch_size)\n",
    "\n",
    "    s, e = 0, 0\n",
    "    for i in range(num_batches):\n",
    "        s, e = i * batch_size, (i + 1) * batch_size\n",
    "        batch_data_dict = {k: v[s:e] for k, v in data_dict.items()}\n",
    "        out[s:e] = f(batch_data_dict)\n",
    "    if e < len(out):\n",
    "        batch_data_dict = {k: v[e:] for k, v in data_dict.items()}\n",
    "        out[e:] = f(batch_data_dict)\n",
    "\n",
    "\n",
    "def extract_image_patch(image, bbox, patch_shape):\n",
    "    \"\"\"Extract image patch from bounding box.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        The full image.\n",
    "    bbox : array_like\n",
    "        The bounding box in format (x, y, width, height).\n",
    "    patch_shape : Optional[array_like]\n",
    "        This parameter can be used to enforce the height and breadth of a patch. First, the 'bbox' \n",
    "        is adjusted to the aspect ratio of the patch's shape, and then it is trimmed to the image's borders.\n",
    " If None, the shape is computed using the bbox argument.\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray | NoneType\n",
    "        An image patch showing the :arg:`bbox`, optionally reshaped to\n",
    "        :arg:`patch_shape`.\n",
    "        Returns None if the bounding box is empty or fully outside of the image\n",
    "        boundaries.\n",
    "    \"\"\"\n",
    "    bbox = np.array(bbox)\n",
    "    if patch_shape is not None:\n",
    "        # correct aspect ratio to patch shape\n",
    "        target_aspect = float(patch_shape[1]) / patch_shape[0]\n",
    "        new_width = target_aspect * bbox[3]\n",
    "        bbox[0] -= (new_width - bbox[2]) / 2\n",
    "        bbox[2] = new_width\n",
    "\n",
    "    # convert to top left, bottom right\n",
    "    bbox[2:] += bbox[:2]\n",
    "    bbox = bbox.astype(np.int)\n",
    "\n",
    "    # clip at image boundaries\n",
    "    bbox[:2] = np.maximum(0, bbox[:2])\n",
    "    bbox[2:] = np.minimum(np.asarray(image.shape[:2][::-1]) - 1, bbox[2:])\n",
    "    if np.any(bbox[:2] >= bbox[2:]):\n",
    "        return None\n",
    "    sx, sy, ex, ey = bbox\n",
    "    image = image[sy:ey, sx:ex]\n",
    "    image = cv2.resize(image, tuple(patch_shape[::-1]))\n",
    "    return image\n",
    "\n",
    "\n",
    "class ImageEncoder(object):\n",
    "\n",
    "    def __init__(self, checkpoint_filename, input_name=\"images\",\n",
    "                 output_name=\"features\"):\n",
    "        self.session = tf.Session()\n",
    "        with tf.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(file_handle.read())\n",
    "        tf.import_graph_def(graph_def, name=\"net\")\n",
    "        self.input_var = tf.get_default_graph().get_tensor_by_name(\n",
    "            \"net/%s:0\" % input_name)\n",
    "        self.output_var = tf.get_default_graph().get_tensor_by_name(\n",
    "            \"net/%s:0\" % output_name)\n",
    "\n",
    "        assert len(self.output_var.get_shape()) == 2\n",
    "        assert len(self.input_var.get_shape()) == 4\n",
    "        self.feature_dim = self.output_var.get_shape().as_list()[-1]\n",
    "        self.image_shape = self.input_var.get_shape().as_list()[1:]\n",
    "\n",
    "    def __call__(self, data_x, batch_size=32):\n",
    "        out = np.zeros((len(data_x), self.feature_dim), np.float32)\n",
    "        _run_in_batches(\n",
    "            lambda x: self.session.run(self.output_var, feed_dict=x),\n",
    "            {self.input_var: data_x}, out, batch_size)\n",
    "        return out\n",
    "\n",
    "\n",
    "def create_box_encoder(model_filename, input_name=\"images\",\n",
    "                       output_name=\"features\", batch_size=32):\n",
    "    image_encoder = ImageEncoder(model_filename, input_name, output_name)\n",
    "    image_shape = image_encoder.image_shape\n",
    "\n",
    "    def encoder(image, boxes):\n",
    "        image_patches = []\n",
    "        for box in boxes:\n",
    "            patch = extract_image_patch(image, box, image_shape[:2])\n",
    "            if patch is None:\n",
    "                print(\"WARNING: Failed to extract image patch: %s.\" % str(box))\n",
    "                patch = np.random.uniform(\n",
    "                    0., 255., image_shape).astype(np.uint8)\n",
    "            image_patches.append(patch)\n",
    "        image_patches = np.asarray(image_patches)\n",
    "        return image_encoder(image_patches, batch_size)\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def generate_detections(encoder, mot_dir, output_dir, detection_dir=None):\n",
    "    \"\"\"Generate detections with features.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoder : Callable[image, ndarray] -> ndarray\n",
    "        The encoder function takes as input a BGR color image and a matrix of\n",
    "        bounding boxes in format `(x, y, w, h)` and returns a matrix of\n",
    "        corresponding feature vectors.\n",
    "    mot_dir : str\n",
    "        Path to the MOTChallenge directory (can be either train or test).\n",
    "    output_dir\n",
    "        Path to the output directory. Will be created if it does not exist.\n",
    "    detection_dir\n",
    "        Path to custom detections. The directory structure should be the default\n",
    "        MOTChallenge structure: `[sequence]/det/det.txt`. If None, uses the\n",
    "        standard MOTChallenge detections.\n",
    "    \"\"\"\n",
    "    if detection_dir is None:\n",
    "        detection_dir = mot_dir\n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except OSError as exception:\n",
    "        if exception.errno == errno.EEXIST and os.path.isdir(output_dir):\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Failed to created output directory '%s'\" % output_dir)\n",
    "\n",
    "    for sequence in os.listdir(mot_dir):\n",
    "        print(\"Processing %s\" % sequence)\n",
    "        sequence_dir = os.path.join(mot_dir, sequence)\n",
    "\n",
    "        image_dir = os.path.join(sequence_dir, \"img1\")\n",
    "        image_filenames = {\n",
    "            int(os.path.splitext(f)[0]): os.path.join(image_dir, f)\n",
    "            for f in os.listdir(image_dir)}\n",
    "\n",
    "        detection_file = os.path.join(\n",
    "            detection_dir, sequence, \"det/det.txt\")\n",
    "        detections_in = np.loadtxt(detection_file, delimiter=',')\n",
    "        detections_out = []\n",
    "\n",
    "        frame_indices = detections_in[:, 0].astype(np.int)\n",
    "        min_frame_idx = frame_indices.astype(np.int).min()\n",
    "        max_frame_idx = frame_indices.astype(np.int).max()\n",
    "        for frame_idx in range(min_frame_idx, max_frame_idx + 1):\n",
    "            print(\"Frame %05d/%05d\" % (frame_idx, max_frame_idx))\n",
    "            mask = frame_indices == frame_idx\n",
    "            rows = detections_in[mask]\n",
    "\n",
    "            if frame_idx not in image_filenames:\n",
    "                print(\"WARNING could not find image for frame %d\" % frame_idx)\n",
    "                continue\n",
    "            bgr_image = cv2.imread(\n",
    "                image_filenames[frame_idx], cv2.IMREAD_COLOR)\n",
    "            features = encoder(bgr_image, rows[:, 2:6].copy())\n",
    "            detections_out += [np.r_[(row, feature)] for row, feature\n",
    "                               in zip(rows, features)]\n",
    "\n",
    "        output_filename = os.path.join(output_dir, \"%s.npy\" % sequence)\n",
    "        np.save(\n",
    "            output_filename, np.asarray(detections_out), allow_pickle=False)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Re-ID feature extractor\")\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        default=\"resources/networks/mars-small128.pb\",\n",
    "        help=\"Path to freezed inference graph protobuf.\")\n",
    "    parser.add_argument(\n",
    "        \"--mot_dir\", help=\"Path to MOTChallenge directory (train or test)\",\n",
    "        required=True)\n",
    "    parser.add_argument(\n",
    "        \"--detection_dir\", help=\"Path to custom detections. Defaults to \"\n",
    "        \"standard MOT detections Directory structure should be the default \"\n",
    "        \"MOTChallenge structure: [sequence]/det/det.txt\", default=None)\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\", help=\"Output directory. Will be created if it does not\"\n",
    "        \" exist.\", default=\"detections\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    encoder = create_box_encoder(args.model, batch_size=32)\n",
    "    generate_detections(encoder, args.mot_dir, args.output_dir,\n",
    "                        args.detection_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
