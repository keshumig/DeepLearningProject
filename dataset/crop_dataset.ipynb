{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c38457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "\n",
    "        def __init__(self,\n",
    "                     DETRAC_images,\n",
    "                     DETRAC_annots,\n",
    "                     output_train,\n",
    "                     occlusion_threshold,\n",
    "                     truncation_threshold,\n",
    "                     occurrences):\n",
    "            self.root_images = DETRAC_images\n",
    "            self.root_annots = DETRAC_annots\n",
    "            self.output_folder = output_train\n",
    "            self.occ_thresh = occlusion_threshold\n",
    "            self.trunc_thresh = truncation_threshold\n",
    "            self.no_of_occurrences = occurrences\n",
    "            self.resize = (100, 100)\n",
    "\n",
    "        def get_sequences(self):\n",
    "            sequences = [x[1] for x in os.walk(self.root_images)]\n",
    "            sequences = sequences[0]\n",
    "            return sequences\n",
    "\n",
    "        def calc_dict(self, frames):\n",
    "            target_id_dict = {}\n",
    "            for frame in frames:\n",
    "                frame_num = int(frame.attrib['num'])\n",
    "                target_list = frame.find('target_list')\n",
    "                targets = target_list.findall('target')\n",
    "                for target in targets:\n",
    "                    target_id = target.attrib['id']\n",
    "                    attribute = target.find('attribute')\n",
    "                    occlusion = target.find('occlusion')\n",
    "\n",
    "                    box = target.find('box')\n",
    "                    width = round(float(box.attrib['width']))\n",
    "                    height = round(float(box.attrib['height']))\n",
    "\n",
    "                    truncation_ratio = float(attribute.attrib['truncation_ratio'])\n",
    "\n",
    "                    if occlusion is not None:\n",
    "                        region_overlap = occlusion.find('region_overlap')\n",
    "                        overlap_width = round(float(region_overlap.attrib['width']))\n",
    "                        overlap_height = round(float(region_overlap.attrib['height']))\n",
    "                        occlusion_ratio = (overlap_width * overlap_height) / (width * height)\n",
    "                    else:\n",
    "                        occlusion_ratio = 0\n",
    "\n",
    "                    if target_id not in list(target_id_dict):\n",
    "                        target_id_dict[target_id] = []\n",
    "\n",
    "                    if occlusion_ratio < self.occ_thresh and truncation_ratio < self.trunc_thresh:\n",
    "                        target_id_dict[target_id].append(frame_num)\n",
    "\n",
    "            for target_id in list(target_id_dict):\n",
    "                no_of_occurrences = len(target_id_dict[target_id])\n",
    "                if no_of_occurrences >= self.no_of_occurrences:\n",
    "                    min_frame = min(target_id_dict[target_id])\n",
    "                    max_frame = max(target_id_dict[target_id])\n",
    "                    sample = random.sample(range(min_frame, max_frame), min(self.no_of_occurrences, len(range(min_frame, max_frame))))\n",
    "                    target_id_dict[target_id] = sample\n",
    "\n",
    "                elif no_of_occurrences < self.no_of_occurrences:\n",
    "                    target_id_dict.pop(target_id)\n",
    "            return target_id_dict\n",
    "\n",
    "        def crop_sequence_images(self, sequences):\n",
    "            max_target_id = 0\n",
    "            for sequence in sequences:\n",
    "                tree = ET.parse(self.root_annots + sequence + '_v3.xml')\n",
    "                root = tree.getroot()\n",
    "                frames = root.findall('frame')\n",
    "                target_id_dict = self.calc_dict(frames)\n",
    "                target_id_list = list(target_id_dict)\n",
    "\n",
    "                for frame in frames:\n",
    "                    target_list = frame.find('target_list')\n",
    "                    targets = target_list.findall('target')\n",
    "                    frame_num = int(frame.attrib['num'])\n",
    "                    for target in targets:\n",
    "                        box = target.find('box')\n",
    "                        target_id = target.attrib['id']\n",
    "                        if target_id in target_id_list:\n",
    "                            frame_list = target_id_dict[target_id]\n",
    "                            if frame_num in frame_list:\n",
    "                                left = round(float(box.attrib['left']))\n",
    "                                top = round(float(box.attrib['top']))\n",
    "                                width = round(float(box.attrib['width']))\n",
    "                                height = round(float(box.attrib['height']))\n",
    "\n",
    "                                right = left + width\n",
    "                                bottom = top + height\n",
    "\n",
    "                                image_frame = \"img\" + str(frame_num).zfill(5) + '.jpg'\n",
    "\n",
    "                                rectangle = (left, top, right, bottom)\n",
    "\n",
    "                                # vehicle_type = attribute.attrib['vehicle_type']\n",
    "                                # truncation_ratio = attribute.attrib['truncation_ratio']\n",
    "                                image = Image.open(self.root_images + sequence + '/' + image_frame)\n",
    "                                image = image.crop(rectangle)\n",
    "                                image = image.resize(self.resize)\n",
    "                                market1501_id = str(int(target_id) + int(max_target_id)).zfill(5) + '_c' + sequence[-5:] \\\n",
    "                                                + 's1_' + str(frame_num).zfill(5) + '_01'\n",
    "                                image.save(self.output_folder + market1501_id + '.jpg')\n",
    "\n",
    "                max_target_id += int(target_id)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Create cropped sequences of vehicles from DETRAC dataset.\")\n",
    "    parser.add_argument(\"--DETRAC_images\",\n",
    "                        help=\"Relative location of DETRAC training images.\",\n",
    "                        default=\"./Insight-MVT_Annotation_Train/\")\n",
    "    parser.add_argument(\"--DETRAC_annots\",\n",
    "                        help=\"Relative location of DETRAC annotation files.\",\n",
    "                        default=\"./DETRAC-Train-Annotations-XML-v3/\")\n",
    "    parser.add_argument(\"--output_train\",\n",
    "                        help=\"Relative output location of cropped training images.\",\n",
    "                        default=\"./DETRAC_cropped/\")\n",
    "    parser.add_argument(\"--occlusion_threshold\",\n",
    "                        help='Ignore images with an occlusion ratio higher than the threshold.',\n",
    "                        default=0.5, type=float)\n",
    "    parser.add_argument(\"--truncation_threshold\",\n",
    "                        help='Ignore images with an truncation ratio higher than the threshold.',\n",
    "                        default=0.5, type=float)\n",
    "    parser.add_argument(\"--occurrences\",\n",
    "                        help='Number of occurrences of each sequence of vehicles.',\n",
    "                        default=100, type=int)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    DETRAC_images = args.DETRAC_images\n",
    "    if not os.path.exists(DETRAC_images):\n",
    "        print('Cannot find path to DETRAC images.')\n",
    "        sys.exit()\n",
    "\n",
    "    DETRAC_annots = args.DETRAC_annots\n",
    "    if not os.path.exists(DETRAC_annots):\n",
    "        print('Cannot find path to DETRAC annotations.')\n",
    "        sys.exit()\n",
    "\n",
    "    output_train = args.output_train\n",
    "    if not os.path.exists(output_train):\n",
    "        os.makedirs(output_train)\n",
    "\n",
    "    if not os.access(output_train, os.W_OK):\n",
    "        print('{} folder is not writeable.'.format(output_train))\n",
    "\n",
    "    occlusion_threshold = args.occlusion_threshold\n",
    "    truncation_threshold = args.truncation_threshold\n",
    "    occurrences = args.occurrences\n",
    "\n",
    "    create_dataset = CreateDataset(DETRAC_images,\n",
    "                                   DETRAC_annots,\n",
    "                                   output_train,\n",
    "                                   occlusion_threshold,\n",
    "                                   truncation_threshold,\n",
    "                                   occurrences)\n",
    "\n",
    "    sequences = create_dataset.get_sequences()\n",
    "\n",
    "    create_dataset.crop_sequence_images(sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
